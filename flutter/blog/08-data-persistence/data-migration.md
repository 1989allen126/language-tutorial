# Flutter æ•°æ®è¿ç§»ç­–ç•¥è¯¦è§£

## ğŸ“– æ¦‚è¿°

æ•°æ®è¿ç§»æ˜¯åº”ç”¨ç‰ˆæœ¬å‡çº§è¿‡ç¨‹ä¸­çš„å…³é”®ç¯èŠ‚ï¼Œæœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç» Flutter åº”ç”¨ä¸­çš„æ•°æ®è¿ç§»ç­–ç•¥ï¼ŒåŒ…æ‹¬æ•°æ®åº“ç‰ˆæœ¬ç®¡ç†ã€è¿ç§»è„šæœ¬è®¾è®¡ã€æ•°æ®å¤‡ä»½æ¢å¤ã€å…¼å®¹æ€§å¤„ç†ç­‰æ ¸å¿ƒæŠ€æœ¯ã€‚

## ğŸ¯ å­¦ä¹ ç›®æ ‡

- æŒæ¡æ•°æ®åº“ç‰ˆæœ¬ç®¡ç†ç­–ç•¥
- ç†è§£æ•°æ®è¿ç§»è„šæœ¬è®¾è®¡åŸåˆ™
- å­¦ä¹ æ•°æ®å¤‡ä»½å’Œæ¢å¤æœºåˆ¶
- å®ç°å‘å‰å’Œå‘åå…¼å®¹æ€§
- æŒæ¡è¿ç§»è¿‡ç¨‹çš„é”™è¯¯å¤„ç†

## ğŸ“š ç›®å½•

1. [ç‰ˆæœ¬ç®¡ç†ç­–ç•¥](#1-ç‰ˆæœ¬ç®¡ç†ç­–ç•¥)
2. [è¿ç§»è„šæœ¬è®¾è®¡](#2-è¿ç§»è„šæœ¬è®¾è®¡)
3. [æ•°æ®å¤‡ä»½æ¢å¤](#3-æ•°æ®å¤‡ä»½æ¢å¤)
4. [å…¼å®¹æ€§å¤„ç†](#4-å…¼å®¹æ€§å¤„ç†)
5. [è¿ç§»ç›‘æ§](#5-è¿ç§»ç›‘æ§)
6. [æ€§èƒ½ä¼˜åŒ–](#6-æ€§èƒ½ä¼˜åŒ–)
7. [æœ€ä½³å®è·µ](#7-æœ€ä½³å®è·µ)

## ğŸ—ï¸ æ•°æ®è¿ç§»æ¶æ„

### è¿ç§»ç³»ç»Ÿæ¶æ„

```mermaid
graph TB
    subgraph "åº”ç”¨å±‚"
        A[åº”ç”¨å¯åŠ¨]
        A1[ç‰ˆæœ¬æ£€æŸ¥]
        A2[è¿ç§»è§¦å‘]
    end

    subgraph "è¿ç§»ç®¡ç†å±‚"
        B[è¿ç§»ç®¡ç†å™¨]
        B1[ç‰ˆæœ¬ç®¡ç†å™¨]
        B2[è„šæœ¬æ‰§è¡Œå™¨]
        B3[å¤‡ä»½ç®¡ç†å™¨]
        B4[å›æ»šç®¡ç†å™¨]
    end

    subgraph "è¿ç§»å¼•æ“"
        C[è¿ç§»å¼•æ“]
        C1[SQLè¿ç§»]
        C2[æ•°æ®è½¬æ¢]
        C3[ç»“æ„å˜æ›´]
        C4[æ•°æ®éªŒè¯]
    end

    subgraph "æ•°æ®å±‚"
        D[æºæ•°æ®åº“]
        D1[å½“å‰ç‰ˆæœ¬]
        D2[å¤‡ä»½æ•°æ®]

        E[ç›®æ ‡æ•°æ®åº“]
        E1[æ–°ç‰ˆæœ¬]
        E2[è¿ç§»æ—¥å¿—]
    end

    subgraph "ç›‘æ§å±‚"
        F[è¿ç§»ç›‘æ§]
        F1[è¿›åº¦è·Ÿè¸ª]
        F2[é”™è¯¯å¤„ç†]
        F3[æ€§èƒ½ç›‘æ§]
    end

    A --> B
    A1 --> B1
    A2 --> B
    B --> C
    B1 --> C
    B2 --> C
    B3 --> D2
    B4 --> D2
    C --> D
    C --> E
    C --> F
    F --> B

    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style D fill:#fff3e0
    style E fill:#fce4ec
    style F fill:#f1f8e9
```

### è¿ç§»æµç¨‹

```mermaid
sequenceDiagram
    participant App as åº”ç”¨å¯åŠ¨
    participant Manager as è¿ç§»ç®¡ç†å™¨
    participant Backup as å¤‡ä»½ç³»ç»Ÿ
    participant Migration as è¿ç§»å¼•æ“
    participant Source as æºæ•°æ®åº“
    participant Target as ç›®æ ‡æ•°æ®åº“
    participant Monitor as ç›‘æ§ç³»ç»Ÿ

    App->>Manager: æ£€æŸ¥ç‰ˆæœ¬
    Manager->>Source: è·å–å½“å‰ç‰ˆæœ¬

    alt éœ€è¦è¿ç§»
        Manager->>Backup: åˆ›å»ºå¤‡ä»½
        Backup-->>Manager: å¤‡ä»½å®Œæˆ
        Manager->>Monitor: å¼€å§‹ç›‘æ§

        loop æ‰§è¡Œè¿ç§»è„šæœ¬
            Manager->>Migration: æ‰§è¡Œè¿ç§»è„šæœ¬
            Migration->>Source: è¯»å–æºæ•°æ®
            Migration->>Target: å†™å…¥ç›®æ ‡æ•°æ®
            Migration-->>Manager: è„šæœ¬å®Œæˆ
            Manager->>Monitor: æ›´æ–°è¿›åº¦
        end

        Manager->>Migration: éªŒè¯è¿ç§»ç»“æœ
        Migration-->>Manager: éªŒè¯å®Œæˆ

        alt è¿ç§»æˆåŠŸ
            Manager->>Target: æ›´æ–°ç‰ˆæœ¬å·
            Manager->>App: è¿ç§»å®Œæˆ
        else è¿ç§»å¤±è´¥
            Manager->>Backup: æ‰§è¡Œå›æ»š
            Backup-->>Manager: å›æ»šå®Œæˆ
            Manager->>App: è¿ç§»å¤±è´¥
        end
    else æ— éœ€è¿ç§»
        Manager->>App: ç›´æ¥å¯åŠ¨
    end
```

### 1. ç‰ˆæœ¬ç®¡ç†ç­–ç•¥

### 1.1 ç‰ˆæœ¬ç®¡ç†ç­–ç•¥å›¾

```mermaid
flowchart TD
    A[ç‰ˆæœ¬æ£€æŸ¥] --> B{å½“å‰ç‰ˆæœ¬}
    B -->|ç‰ˆæœ¬1| C[æ‰§è¡Œ1åˆ°2è¿ç§»]
    B -->|ç‰ˆæœ¬2| D[æ‰§è¡Œ2åˆ°3è¿ç§»]
    B -->|ç‰ˆæœ¬3| E[æ‰§è¡Œ3åˆ°4è¿ç§»]
    B -->|æœ€æ–°ç‰ˆæœ¬| F[æ— éœ€è¿ç§»]

    C --> G{è¿ç§»ç±»å‹}
    D --> G
    E --> G

    G -->|ç»“æ„å˜æ›´| H[è¡¨ç»“æ„è¿ç§»]
    G -->|æ•°æ®å˜æ›´| I[æ•°æ®è¿ç§»]
    G -->|ç´¢å¼•å˜æ›´| J[ç´¢å¼•é‡å»º]
    G -->|é…ç½®å˜æ›´| K[é…ç½®æ›´æ–°]

    H --> L{å˜æ›´ç±»å‹}
    L -->|æ·»åŠ å­—æ®µ| M[ALTER TABLE ADD]
    L -->|åˆ é™¤å­—æ®µ| N[æ•°æ®å¤‡ä»½ååˆ é™¤]
    L -->|ä¿®æ”¹å­—æ®µ| O[ç±»å‹è½¬æ¢]
    L -->|é‡å‘½åå­—æ®µ| P[åˆ›å»ºæ–°å­—æ®µ]

    I --> Q{æ•°æ®è½¬æ¢}
    Q -->|æ ¼å¼è½¬æ¢| R[æ•°æ®æ ¼å¼åŒ–]
    Q -->|ç¼–ç è½¬æ¢| S[å­—ç¬¦ç¼–ç è½¬æ¢]
    Q -->|ç±»å‹è½¬æ¢| T[æ•°æ®ç±»å‹è½¬æ¢]

    M --> U[éªŒè¯è¿ç§»]
    N --> U
    O --> U
    P --> U
    R --> U
    S --> U
    T --> U
    J --> U
    K --> U

    U --> V{éªŒè¯ç»“æœ}
    V -->|æˆåŠŸ| W[æ›´æ–°ç‰ˆæœ¬å·]
    V -->|å¤±è´¥| X[æ‰§è¡Œå›æ»š]

    style A fill:#e1f5fe
    style G fill:#f3e5f5
    style L fill:#e8f5e8
    style Q fill:#fff3e0
    style U fill:#fce4ec
    style W fill:#f1f8e9
    style X fill:#ffebee
```

### 1.2 æ•°æ®åº“ç‰ˆæœ¬ç®¡ç†

```dart
// æ•°æ®åº“ç‰ˆæœ¬ä¿¡æ¯
class DatabaseVersion {
  final int version;
  final String description;
  final DateTime releaseDate;
  final List<String> migrationScripts;
  final bool isBreakingChange;

  const DatabaseVersion({
    required this.version,
    required this.description,
    required this.releaseDate,
    required this.migrationScripts,
    this.isBreakingChange = false,
  });

  Map<String, dynamic> toJson() {
    return {
      'version': version,
      'description': description,
      'releaseDate': releaseDate.toIso8601String(),
      'migrationScripts': migrationScripts,
      'isBreakingChange': isBreakingChange,
    };
  }

  factory DatabaseVersion.fromJson(Map<String, dynamic> json) {
    return DatabaseVersion(
      version: json['version'],
      description: json['description'],
      releaseDate: DateTime.parse(json['releaseDate']),
      migrationScripts: List<String>.from(json['migrationScripts']),
      isBreakingChange: json['isBreakingChange'] ?? false,
    );
  }
}

// ç‰ˆæœ¬ç®¡ç†å™¨
class DatabaseVersionManager {
  static const String _versionKey = 'database_version';
  static const String _migrationHistoryKey = 'migration_history';

  final SharedPreferences _prefs;
  final List<DatabaseVersion> _versions;

  DatabaseVersionManager({
    required SharedPreferences prefs,
    required List<DatabaseVersion> versions,
  }) : _prefs = prefs,
       _versions = versions..sort((a, b) => a.version.compareTo(b.version));

  // è·å–å½“å‰æ•°æ®åº“ç‰ˆæœ¬
  int getCurrentVersion() {
    return _prefs.getInt(_versionKey) ?? 0;
  }

  // è·å–ç›®æ ‡ç‰ˆæœ¬
  int getTargetVersion() {
    return _versions.isNotEmpty ? _versions.last.version : 0;
  }

  // æ£€æŸ¥æ˜¯å¦éœ€è¦è¿ç§»
  bool needsMigration() {
    return getCurrentVersion() < getTargetVersion();
  }

  // è·å–è¿ç§»è·¯å¾„
  List<DatabaseVersion> getMigrationPath() {
    final currentVersion = getCurrentVersion();
    return _versions
        .where((v) => v.version > currentVersion)
        .toList();
  }

  // è®°å½•è¿ç§»å†å²
  Future<void> recordMigration(DatabaseVersion version) async {
    final history = getMigrationHistory();
    history.add(MigrationRecord(
      version: version.version,
      description: version.description,
      timestamp: DateTime.now(),
      success: true,
    ));

    await _saveMigrationHistory(history);
    await _prefs.setInt(_versionKey, version.version);
  }

  // è·å–è¿ç§»å†å²
  List<MigrationRecord> getMigrationHistory() {
    final historyJson = _prefs.getStringList(_migrationHistoryKey) ?? [];
    return historyJson
        .map((json) => MigrationRecord.fromJson(jsonDecode(json)))
        .toList();
  }

  Future<void> _saveMigrationHistory(List<MigrationRecord> history) async {
    final historyJson = history
        .map((record) => jsonEncode(record.toJson()))
        .toList();
    await _prefs.setStringList(_migrationHistoryKey, historyJson);
  }

  // å›æ»šåˆ°æŒ‡å®šç‰ˆæœ¬
  Future<void> rollbackToVersion(int targetVersion) async {
    if (targetVersion >= getCurrentVersion()) {
      throw Exception('Cannot rollback to a higher or equal version');
    }

    await _prefs.setInt(_versionKey, targetVersion);
  }
}

// è¿ç§»è®°å½•
class MigrationRecord {
  final int version;
  final String description;
  final DateTime timestamp;
  final bool success;
  final String? errorMessage;

  const MigrationRecord({
    required this.version,
    required this.description,
    required this.timestamp,
    required this.success,
    this.errorMessage,
  });

  Map<String, dynamic> toJson() {
    return {
      'version': version,
      'description': description,
      'timestamp': timestamp.toIso8601String(),
      'success': success,
      'errorMessage': errorMessage,
    };
  }

  factory MigrationRecord.fromJson(Map<String, dynamic> json) {
    return MigrationRecord(
      version: json['version'],
      description: json['description'],
      timestamp: DateTime.parse(json['timestamp']),
      success: json['success'],
      errorMessage: json['errorMessage'],
    );
  }
}
```

### 1.2 ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥

```dart
// å…¼å®¹æ€§æ£€æŸ¥å™¨
class CompatibilityChecker {
  final List<DatabaseVersion> _versions;

  CompatibilityChecker(this._versions);

  // æ£€æŸ¥ç‰ˆæœ¬å…¼å®¹æ€§
  CompatibilityResult checkCompatibility(
    int fromVersion,
    int toVersion,
  ) {
    final migrationPath = _getMigrationPath(fromVersion, toVersion);

    if (migrationPath.isEmpty) {
      return CompatibilityResult.compatible();
    }

    final hasBreakingChanges = migrationPath
        .any((version) => version.isBreakingChange);

    final warnings = <String>[];
    final errors = <String>[];

    for (final version in migrationPath) {
      if (version.isBreakingChange) {
        warnings.add(
          'Version ${version.version} contains breaking changes: '
          '${version.description}',
        );
      }

      // æ£€æŸ¥ç‰¹å®šçš„å…¼å®¹æ€§é—®é¢˜
      final issues = _checkVersionSpecificIssues(version);
      errors.addAll(issues);
    }

    return CompatibilityResult(
      isCompatible: errors.isEmpty,
      hasBreakingChanges: hasBreakingChanges,
      warnings: warnings,
      errors: errors,
      migrationPath: migrationPath,
    );
  }

  List<DatabaseVersion> _getMigrationPath(int fromVersion, int toVersion) {
    return _versions
        .where((v) => v.version > fromVersion && v.version <= toVersion)
        .toList();
  }

  List<String> _checkVersionSpecificIssues(DatabaseVersion version) {
    final issues = <String>[];

    // æ£€æŸ¥ç‰¹å®šç‰ˆæœ¬çš„å·²çŸ¥é—®é¢˜
    switch (version.version) {
      case 2:
        // æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„å­˜å‚¨ç©ºé—´
        if (!_hasEnoughStorage()) {
          issues.add('Insufficient storage space for migration to version 2');
        }
        break;
      case 5:
        // æ£€æŸ¥æ˜¯å¦æ”¯æŒæ–°çš„æ•°æ®æ ¼å¼
        if (!_supportsNewDataFormat()) {
          issues.add('Device does not support new data format in version 5');
        }
        break;
    }

    return issues;
  }

  bool _hasEnoughStorage() {
    // å®ç°å­˜å‚¨ç©ºé—´æ£€æŸ¥é€»è¾‘
    return true;
  }

  bool _supportsNewDataFormat() {
    // å®ç°æ•°æ®æ ¼å¼æ”¯æŒæ£€æŸ¥é€»è¾‘
    return true;
  }
}

// å…¼å®¹æ€§æ£€æŸ¥ç»“æœ
class CompatibilityResult {
  final bool isCompatible;
  final bool hasBreakingChanges;
  final List<String> warnings;
  final List<String> errors;
  final List<DatabaseVersion> migrationPath;

  const CompatibilityResult({
    required this.isCompatible,
    required this.hasBreakingChanges,
    required this.warnings,
    required this.errors,
    required this.migrationPath,
  });

  factory CompatibilityResult.compatible() {
    return const CompatibilityResult(
      isCompatible: true,
      hasBreakingChanges: false,
      warnings: [],
      errors: [],
      migrationPath: [],
    );
  }
}
```

## 2. è¿ç§»è„šæœ¬è®¾è®¡

### 2.1 è¿ç§»è„šæœ¬æ¥å£

```dart
// è¿ç§»è„šæœ¬æ¥å£
abstract class MigrationScript {
  int get version;
  String get description;

  Future<void> upgrade(Database db);
  Future<void> downgrade(Database db);
  Future<bool> validate(Database db);
}

// åŸºç¡€è¿ç§»è„šæœ¬
abstract class BaseMigrationScript implements MigrationScript {
  @override
  final int version;

  @override
  final String description;

  const BaseMigrationScript({
    required this.version,
    required this.description,
  });

  @override
  Future<bool> validate(Database db) async {
    try {
      // åŸºç¡€éªŒè¯é€»è¾‘
      await _validateTableStructure(db);
      await _validateDataIntegrity(db);
      return true;
    } catch (e) {
      debugPrint('Migration validation failed: $e');
      return false;
    }
  }

  Future<void> _validateTableStructure(Database db) async {
    // éªŒè¯è¡¨ç»“æ„
  }

  Future<void> _validateDataIntegrity(Database db) async {
    // éªŒè¯æ•°æ®å®Œæ•´æ€§
  }

  // è¾…åŠ©æ–¹æ³•
  Future<bool> tableExists(Database db, String tableName) async {
    final result = await db.rawQuery(
      "SELECT name FROM sqlite_master WHERE type='table' AND name=?",
      [tableName],
    );
    return result.isNotEmpty;
  }

  Future<bool> columnExists(
    Database db,
    String tableName,
    String columnName,
  ) async {
    final result = await db.rawQuery('PRAGMA table_info($tableName)');
    return result.any((row) => row['name'] == columnName);
  }

  Future<void> addColumnIfNotExists(
    Database db,
    String tableName,
    String columnName,
    String columnDefinition,
  ) async {
    if (!await columnExists(db, tableName, columnName)) {
      await db.execute(
        'ALTER TABLE $tableName ADD COLUMN $columnName $columnDefinition',
      );
    }
  }

  Future<void> createIndexIfNotExists(
    Database db,
    String indexName,
    String tableName,
    List<String> columns,
  ) async {
    final result = await db.rawQuery(
      "SELECT name FROM sqlite_master WHERE type='index' AND name=?",
      [indexName],
    );

    if (result.isEmpty) {
      final columnList = columns.join(', ');
      await db.execute(
        'CREATE INDEX $indexName ON $tableName ($columnList)',
      );
    }
  }
}
```

### 2.2 å…·ä½“è¿ç§»è„šæœ¬ç¤ºä¾‹

```dart
// ç‰ˆæœ¬1åˆ°ç‰ˆæœ¬2çš„è¿ç§»è„šæœ¬
class Migration_1_to_2 extends BaseMigrationScript {
  const Migration_1_to_2() : super(
    version: 2,
    description: 'Add user profile table and update user table',
  );

  @override
  Future<void> upgrade(Database db) async {
    await db.transaction((txn) async {
      // åˆ›å»ºç”¨æˆ·é…ç½®è¡¨
      await txn.execute('''
        CREATE TABLE user_profiles (
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          user_id INTEGER NOT NULL,
          avatar_url TEXT,
          bio TEXT,
          preferences TEXT,
          created_at INTEGER NOT NULL,
          updated_at INTEGER NOT NULL,
          FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE
        )
      ''');

      // ä¸ºç”¨æˆ·è¡¨æ·»åŠ æ–°åˆ—
      await addColumnIfNotExists(
        txn,
        'users',
        'last_login_at',
        'INTEGER',
      );

      await addColumnIfNotExists(
        txn,
        'users',
        'is_verified',
        'INTEGER DEFAULT 0',
      );

      // åˆ›å»ºç´¢å¼•
      await createIndexIfNotExists(
        txn,
        'idx_user_profiles_user_id',
        'user_profiles',
        ['user_id'],
      );

      await createIndexIfNotExists(
        txn,
        'idx_users_last_login',
        'users',
        ['last_login_at'],
      );

      // è¿ç§»ç°æœ‰æ•°æ®
      await _migrateExistingData(txn);
    });
  }

  @override
  Future<void> downgrade(Database db) async {
    await db.transaction((txn) async {
      // åˆ é™¤ç”¨æˆ·é…ç½®è¡¨
      await txn.execute('DROP TABLE IF EXISTS user_profiles');

      // åˆ é™¤ç´¢å¼•
      await txn.execute('DROP INDEX IF EXISTS idx_user_profiles_user_id');
      await txn.execute('DROP INDEX IF EXISTS idx_users_last_login');

      // æ³¨æ„ï¼šSQLiteä¸æ”¯æŒåˆ é™¤åˆ—ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¿ç•™æ–°æ·»åŠ çš„åˆ—
      // åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯èƒ½éœ€è¦é‡å»ºè¡¨æ¥å®Œå…¨å›æ»š
    });
  }

  Future<void> _migrateExistingData(DatabaseExecutor db) async {
    // ä¸ºç°æœ‰ç”¨æˆ·åˆ›å»ºé»˜è®¤é…ç½®
    final users = await db.query('users');

    for (final user in users) {
      await db.insert('user_profiles', {
        'user_id': user['id'],
        'preferences': '{}', // é»˜è®¤ç©ºé…ç½®
        'created_at': DateTime.now().millisecondsSinceEpoch,
        'updated_at': DateTime.now().millisecondsSinceEpoch,
      });
    }
  }

  @override
  Future<bool> validate(Database db) async {
    if (!await super.validate(db)) {
      return false;
    }

    // éªŒè¯æ–°è¡¨æ˜¯å¦å­˜åœ¨
    if (!await tableExists(db, 'user_profiles')) {
      return false;
    }

    // éªŒè¯æ–°åˆ—æ˜¯å¦å­˜åœ¨
    if (!await columnExists(db, 'users', 'last_login_at')) {
      return false;
    }

    if (!await columnExists(db, 'users', 'is_verified')) {
      return false;
    }

    // éªŒè¯æ•°æ®å®Œæ•´æ€§
    final userCount = Sqflite.firstIntValue(
      await db.rawQuery('SELECT COUNT(*) FROM users'),
    ) ?? 0;

    final profileCount = Sqflite.firstIntValue(
      await db.rawQuery('SELECT COUNT(*) FROM user_profiles'),
    ) ?? 0;

    // æ¯ä¸ªç”¨æˆ·éƒ½åº”è¯¥æœ‰ä¸€ä¸ªé…ç½®
    return userCount == profileCount;
  }
}

// ç‰ˆæœ¬2åˆ°ç‰ˆæœ¬3çš„è¿ç§»è„šæœ¬ï¼ˆæ•°æ®æ ¼å¼å˜æ›´ï¼‰
class Migration_2_to_3 extends BaseMigrationScript {
  const Migration_2_to_3() : super(
    version: 3,
    description: 'Convert preferences from JSON string to normalized tables',
  );

  @override
  Future<void> upgrade(Database db) async {
    await db.transaction((txn) async {
      // åˆ›å»ºæ–°çš„åå¥½è®¾ç½®è¡¨
      await txn.execute('''
        CREATE TABLE user_preferences (
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          user_id INTEGER NOT NULL,
          preference_key TEXT NOT NULL,
          preference_value TEXT,
          created_at INTEGER NOT NULL,
          updated_at INTEGER NOT NULL,
          FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE,
          UNIQUE(user_id, preference_key)
        )
      ''');

      // è¿ç§»ç°æœ‰çš„JSONåå¥½è®¾ç½®
      await _migratePreferences(txn);

      // åˆ›å»ºä¸´æ—¶è¡¨æ¥é‡å»ºuser_profilesè¡¨ï¼ˆç§»é™¤preferencesåˆ—ï¼‰
      await txn.execute('''
        CREATE TABLE user_profiles_new (
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          user_id INTEGER NOT NULL,
          avatar_url TEXT,
          bio TEXT,
          created_at INTEGER NOT NULL,
          updated_at INTEGER NOT NULL,
          FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE
        )
      ''');

      // å¤åˆ¶æ•°æ®ï¼ˆé™¤äº†preferencesåˆ—ï¼‰
      await txn.execute('''
        INSERT INTO user_profiles_new
        (id, user_id, avatar_url, bio, created_at, updated_at)
        SELECT id, user_id, avatar_url, bio, created_at, updated_at
        FROM user_profiles
      ''');

      // åˆ é™¤æ—§è¡¨å¹¶é‡å‘½åæ–°è¡¨
      await txn.execute('DROP TABLE user_profiles');
      await txn.execute(
        'ALTER TABLE user_profiles_new RENAME TO user_profiles',
      );

      // é‡å»ºç´¢å¼•
      await createIndexIfNotExists(
        txn,
        'idx_user_profiles_user_id',
        'user_profiles',
        ['user_id'],
      );

      await createIndexIfNotExists(
        txn,
        'idx_user_preferences_user_key',
        'user_preferences',
        ['user_id', 'preference_key'],
      );
    });
  }

  @override
  Future<void> downgrade(Database db) async {
    await db.transaction((txn) async {
      // é‡å»ºå¸¦preferencesåˆ—çš„user_profilesè¡¨
      await txn.execute('''
        CREATE TABLE user_profiles_old (
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          user_id INTEGER NOT NULL,
          avatar_url TEXT,
          bio TEXT,
          preferences TEXT,
          created_at INTEGER NOT NULL,
          updated_at INTEGER NOT NULL,
          FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE
        )
      ''');

      // å¤åˆ¶æ•°æ®å¹¶é‡å»ºpreferences JSON
      await _restorePreferences(txn);

      // åˆ é™¤æ–°è¡¨
      await txn.execute('DROP TABLE user_preferences');
      await txn.execute('DROP TABLE user_profiles');
      await txn.execute(
        'ALTER TABLE user_profiles_old RENAME TO user_profiles',
      );
    });
  }

  Future<void> _migratePreferences(DatabaseExecutor db) async {
    final profiles = await db.query('user_profiles');

    for (final profile in profiles) {
      final preferencesJson = profile['preferences'] as String?;
      if (preferencesJson != null && preferencesJson.isNotEmpty) {
        try {
          final preferences = jsonDecode(preferencesJson) as Map<String, dynamic>;

          for (final entry in preferences.entries) {
            await db.insert('user_preferences', {
              'user_id': profile['user_id'],
              'preference_key': entry.key,
              'preference_value': entry.value?.toString(),
              'created_at': DateTime.now().millisecondsSinceEpoch,
              'updated_at': DateTime.now().millisecondsSinceEpoch,
            });
          }
        } catch (e) {
          debugPrint('Failed to migrate preferences for user ${profile['user_id']}: $e');
        }
      }
    }
  }

  Future<void> _restorePreferences(DatabaseExecutor db) async {
    final profiles = await db.query('user_profiles');

    for (final profile in profiles) {
      final userId = profile['user_id'];

      // è·å–ç”¨æˆ·çš„æ‰€æœ‰åå¥½è®¾ç½®
      final preferences = await db.query(
        'user_preferences',
        where: 'user_id = ?',
        whereArgs: [userId],
      );

      // é‡å»ºJSON
      final preferencesMap = <String, dynamic>{};
      for (final pref in preferences) {
        preferencesMap[pref['preference_key'] as String] =
            pref['preference_value'];
      }

      // æ’å…¥åˆ°æ–°è¡¨
      await db.insert('user_profiles_old', {
        'id': profile['id'],
        'user_id': profile['user_id'],
        'avatar_url': profile['avatar_url'],
        'bio': profile['bio'],
        'preferences': jsonEncode(preferencesMap),
        'created_at': profile['created_at'],
        'updated_at': profile['updated_at'],
      });
    }
  }
}
```

### 2.3 è¿ç§»æ‰§è¡Œå™¨

```dart
// è¿ç§»æ‰§è¡Œå™¨
class MigrationExecutor {
  final Database _database;
  final DatabaseVersionManager _versionManager;
  final List<MigrationScript> _migrations;
  final MigrationProgressCallback? _progressCallback;

  MigrationExecutor({
    required Database database,
    required DatabaseVersionManager versionManager,
    required List<MigrationScript> migrations,
    MigrationProgressCallback? progressCallback,
  }) : _database = database,
       _versionManager = versionManager,
       _migrations = migrations,
       _progressCallback = progressCallback {
    // æŒ‰ç‰ˆæœ¬å·æ’åº
    _migrations.sort((a, b) => a.version.compareTo(b.version));
  }

  // æ‰§è¡Œè¿ç§»
  Future<MigrationResult> executeMigrations() async {
    if (!_versionManager.needsMigration()) {
      return MigrationResult.success(
        fromVersion: _versionManager.getCurrentVersion(),
        toVersion: _versionManager.getTargetVersion(),
        migrationsExecuted: [],
      );
    }

    final migrationPath = _versionManager.getMigrationPath();
    final migrationsToExecute = _getMigrationsForPath(migrationPath);

    final executedMigrations = <int>[];
    final errors = <String>[];

    _progressCallback?.call(MigrationProgress(
      currentStep: 0,
      totalSteps: migrationsToExecute.length,
      currentMigration: null,
      status: MigrationStatus.started,
    ));

    for (int i = 0; i < migrationsToExecute.length; i++) {
      final migration = migrationsToExecute[i];

      _progressCallback?.call(MigrationProgress(
        currentStep: i + 1,
        totalSteps: migrationsToExecute.length,
        currentMigration: migration,
        status: MigrationStatus.executing,
      ));

      try {
        await _executeSingleMigration(migration);
        executedMigrations.add(migration.version);

        // è®°å½•æˆåŠŸçš„è¿ç§»
        await _versionManager.recordMigration(
          DatabaseVersion(
            version: migration.version,
            description: migration.description,
            releaseDate: DateTime.now(),
            migrationScripts: [],
          ),
        );
      } catch (e) {
        final errorMessage = 'Migration ${migration.version} failed: $e';
        errors.add(errorMessage);

        _progressCallback?.call(MigrationProgress(
          currentStep: i + 1,
          totalSteps: migrationsToExecute.length,
          currentMigration: migration,
          status: MigrationStatus.failed,
          error: errorMessage,
        ));

        // è¿ç§»å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ
        break;
      }
    }

    final finalStatus = errors.isEmpty
        ? MigrationStatus.completed
        : MigrationStatus.failed;

    _progressCallback?.call(MigrationProgress(
      currentStep: migrationsToExecute.length,
      totalSteps: migrationsToExecute.length,
      currentMigration: null,
      status: finalStatus,
    ));

    if (errors.isEmpty) {
      return MigrationResult.success(
        fromVersion: _versionManager.getCurrentVersion(),
        toVersion: _versionManager.getTargetVersion(),
        migrationsExecuted: executedMigrations,
      );
    } else {
      return MigrationResult.failure(
        fromVersion: _versionManager.getCurrentVersion(),
        toVersion: _versionManager.getTargetVersion(),
        migrationsExecuted: executedMigrations,
        errors: errors,
      );
    }
  }

  Future<void> _executeSingleMigration(MigrationScript migration) async {
    // åˆ›å»ºå¤‡ä»½ç‚¹
    await _createBackupPoint(migration.version);

    try {
      // æ‰§è¡Œè¿ç§»
      await migration.upgrade(_database);

      // éªŒè¯è¿ç§»ç»“æœ
      final isValid = await migration.validate(_database);
      if (!isValid) {
        throw Exception('Migration validation failed');
      }
    } catch (e) {
      // è¿ç§»å¤±è´¥ï¼Œå°è¯•æ¢å¤
      await _restoreFromBackup(migration.version);
      rethrow;
    }
  }

  List<MigrationScript> _getMigrationsForPath(
    List<DatabaseVersion> migrationPath,
  ) {
    final targetVersions = migrationPath.map((v) => v.version).toSet();
    return _migrations
        .where((m) => targetVersions.contains(m.version))
        .toList();
  }

  Future<void> _createBackupPoint(int version) async {
    // å®ç°æ•°æ®åº“å¤‡ä»½é€»è¾‘
    // å¯ä»¥å¤åˆ¶æ•°æ®åº“æ–‡ä»¶æˆ–å¯¼å‡ºæ•°æ®
  }

  Future<void> _restoreFromBackup(int version) async {
    // å®ç°æ•°æ®åº“æ¢å¤é€»è¾‘
    // ä»å¤‡ä»½ç‚¹æ¢å¤æ•°æ®åº“
  }
}

// è¿ç§»è¿›åº¦å›è°ƒ
typedef MigrationProgressCallback = void Function(MigrationProgress progress);

// è¿ç§»è¿›åº¦
class MigrationProgress {
  final int currentStep;
  final int totalSteps;
  final MigrationScript? currentMigration;
  final MigrationStatus status;
  final String? error;

  const MigrationProgress({
    required this.currentStep,
    required this.totalSteps,
    required this.currentMigration,
    required this.status,
    this.error,
  });

  double get progress => totalSteps > 0 ? currentStep / totalSteps : 0.0;
}

// è¿ç§»çŠ¶æ€
enum MigrationStatus {
  started,
  executing,
  completed,
  failed,
}

// è¿ç§»ç»“æœ
class MigrationResult {
  final bool isSuccess;
  final int fromVersion;
  final int toVersion;
  final List<int> migrationsExecuted;
  final List<String> errors;

  const MigrationResult._(
    this.isSuccess,
    this.fromVersion,
    this.toVersion,
    this.migrationsExecuted,
    this.errors,
  );

  factory MigrationResult.success({
    required int fromVersion,
    required int toVersion,
    required List<int> migrationsExecuted,
  }) {
    return MigrationResult._(
      true,
      fromVersion,
      toVersion,
      migrationsExecuted,
      [],
    );
  }

  factory MigrationResult.failure({
    required int fromVersion,
    required int toVersion,
    required List<int> migrationsExecuted,
    required List<String> errors,
  }) {
    return MigrationResult._(
      false,
      fromVersion,
      toVersion,
      migrationsExecuted,
      errors,
    );
  }
}
```

## 3. æ•°æ®å¤‡ä»½æ¢å¤

### 3.1 å¤‡ä»½ç®¡ç†å™¨

```dart
// å¤‡ä»½ç®¡ç†å™¨
class BackupManager {
  final String _backupDirectory;
  final int _maxBackups;

  BackupManager({
    required String backupDirectory,
    int maxBackups = 5,
  }) : _backupDirectory = backupDirectory,
       _maxBackups = maxBackups;

  // åˆ›å»ºæ•°æ®åº“å¤‡ä»½
  Future<BackupInfo> createBackup(
    String databasePath, {
    String? description,
  }) async {
    final timestamp = DateTime.now();
    final backupFileName = 'backup_${timestamp.millisecondsSinceEpoch}.db';
    final backupPath = path.join(_backupDirectory, backupFileName);

    // ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
    final backupDir = Directory(_backupDirectory);
    if (!await backupDir.exists()) {
      await backupDir.create(recursive: true);
    }

    // å¤åˆ¶æ•°æ®åº“æ–‡ä»¶
    final sourceFile = File(databasePath);
    await sourceFile.copy(backupPath);

    // åˆ›å»ºå¤‡ä»½ä¿¡æ¯
    final backupInfo = BackupInfo(
      id: timestamp.millisecondsSinceEpoch.toString(),
      filePath: backupPath,
      originalPath: databasePath,
      timestamp: timestamp,
      description: description ?? 'Auto backup',
      size: await sourceFile.length(),
    );

    // ä¿å­˜å¤‡ä»½ä¿¡æ¯
    await _saveBackupInfo(backupInfo);

    // æ¸…ç†æ—§å¤‡ä»½
    await _cleanupOldBackups();

    return backupInfo;
  }

  // æ¢å¤æ•°æ®åº“
  Future<void> restoreBackup(
    String backupId,
    String targetDatabasePath,
  ) async {
    final backupInfo = await getBackupInfo(backupId);
    if (backupInfo == null) {
      throw Exception('Backup not found: $backupId');
    }

    final backupFile = File(backupInfo.filePath);
    if (!await backupFile.exists()) {
      throw Exception('Backup file not found: ${backupInfo.filePath}');
    }

    // åˆ›å»ºå½“å‰æ•°æ®åº“çš„å¤‡ä»½ï¼ˆä»¥é˜²æ¢å¤å¤±è´¥ï¼‰
    final currentBackup = await createBackup(
      targetDatabasePath,
      description: 'Pre-restore backup',
    );

    try {
      // æ¢å¤æ•°æ®åº“
      await backupFile.copy(targetDatabasePath);
    } catch (e) {
      // æ¢å¤å¤±è´¥ï¼Œå›æ»šåˆ°ä¹‹å‰çš„çŠ¶æ€
      await restoreBackup(currentBackup.id, targetDatabasePath);
      rethrow;
    }
  }

  // è·å–æ‰€æœ‰å¤‡ä»½
  Future<List<BackupInfo>> getAllBackups() async {
    final backupInfoFile = File(path.join(_backupDirectory, 'backups.json'));

    if (!await backupInfoFile.exists()) {
      return [];
    }

    final content = await backupInfoFile.readAsString();
    final List<dynamic> backupList = jsonDecode(content);

    return backupList
        .map((json) => BackupInfo.fromJson(json))
        .toList()
      ..sort((a, b) => b.timestamp.compareTo(a.timestamp));
  }

  // è·å–ç‰¹å®šå¤‡ä»½ä¿¡æ¯
  Future<BackupInfo?> getBackupInfo(String backupId) async {
    final allBackups = await getAllBackups();
    try {
      return allBackups.firstWhere((backup) => backup.id == backupId);
    } catch (e) {
      return null;
    }
  }

  // åˆ é™¤å¤‡ä»½
  Future<void> deleteBackup(String backupId) async {
    final backupInfo = await getBackupInfo(backupId);
    if (backupInfo == null) {
      return;
    }

    // åˆ é™¤å¤‡ä»½æ–‡ä»¶
    final backupFile = File(backupInfo.filePath);
    if (await backupFile.exists()) {
      await backupFile.delete();
    }

    // æ›´æ–°å¤‡ä»½ä¿¡æ¯
    final allBackups = await getAllBackups();
    allBackups.removeWhere((backup) => backup.id == backupId);
    await _saveAllBackupInfo(allBackups);
  }

  // éªŒè¯å¤‡ä»½å®Œæ•´æ€§
  Future<bool> validateBackup(String backupId) async {
    final backupInfo = await getBackupInfo(backupId);
    if (backupInfo == null) {
      return false;
    }

    final backupFile = File(backupInfo.filePath);
    if (!await backupFile.exists()) {
      return false;
    }

    // æ£€æŸ¥æ–‡ä»¶å¤§å°
    final currentSize = await backupFile.length();
    if (currentSize != backupInfo.size) {
      return false;
    }

    // å°è¯•æ‰“å¼€æ•°æ®åº“æ–‡ä»¶
    try {
      final db = await openDatabase(
        backupInfo.filePath,
        readOnly: true,
      );
      await db.close();
      return true;
    } catch (e) {
      return false;
    }
  }

  Future<void> _saveBackupInfo(BackupInfo backupInfo) async {
    final allBackups = await getAllBackups();
    allBackups.add(backupInfo);
    await _saveAllBackupInfo(allBackups);
  }

  Future<void> _saveAllBackupInfo(List<BackupInfo> backups) async {
    final backupInfoFile = File(path.join(_backupDirectory, 'backups.json'));
    final backupList = backups.map((backup) => backup.toJson()).toList();
    await backupInfoFile.writeAsString(jsonEncode(backupList));
  }

  Future<void> _cleanupOldBackups() async {
    final allBackups = await getAllBackups();

    if (allBackups.length <= _maxBackups) {
      return;
    }

    // æŒ‰æ—¶é—´æ’åºï¼Œä¿ç•™æœ€æ–°çš„å¤‡ä»½
    allBackups.sort((a, b) => b.timestamp.compareTo(a.timestamp));

    final backupsToDelete = allBackups.skip(_maxBackups).toList();

    for (final backup in backupsToDelete) {
      await deleteBackup(backup.id);
    }
  }
}

// å¤‡ä»½ä¿¡æ¯
class BackupInfo {
  final String id;
  final String filePath;
  final String originalPath;
  final DateTime timestamp;
  final String description;
  final int size;

  const BackupInfo({
    required this.id,
    required this.filePath,
    required this.originalPath,
    required this.timestamp,
    required this.description,
    required this.size,
  });

  Map<String, dynamic> toJson() {
    return {
      'id': id,
      'filePath': filePath,
      'originalPath': originalPath,
      'timestamp': timestamp.toIso8601String(),
      'description': description,
      'size': size,
    };
  }

  factory BackupInfo.fromJson(Map<String, dynamic> json) {
    return BackupInfo(
      id: json['id'],
      filePath: json['filePath'],
      originalPath: json['originalPath'],
      timestamp: DateTime.parse(json['timestamp']),
      description: json['description'],
      size: json['size'],
    );
  }
}
```

## ğŸ“š æ€»ç»“

### è¿ç§»ç­–ç•¥å¯¹æ¯”

| ç­–ç•¥     | ä¼˜ç‚¹               | ç¼ºç‚¹     | é€‚ç”¨åœºæ™¯       |
| -------- | ------------------ | -------- | -------------- |
| å¢é‡è¿ç§» | å‡çº§å¿«é€Ÿï¼Œæ”¯æŒå›æ»š | å®ç°å¤æ‚ | é¢‘ç¹æ›´æ–°çš„åº”ç”¨ |
| å…¨é‡è¿ç§» | å®ç°ç®€å•ï¼Œæ•°æ®ä¸€è‡´ | å‡çº§ç¼“æ…¢ | å¤§ç‰ˆæœ¬å‡çº§     |
| åœ¨çº¿è¿ç§» | ä¸ä¸­æ–­æœåŠ¡         | æŠ€æœ¯å¤æ‚ | ä¼ä¸šçº§åº”ç”¨     |
| ç¦»çº¿è¿ç§» | å®‰å…¨å¯é            | æœåŠ¡ä¸­æ–­ | ç»´æŠ¤çª—å£å‡çº§   |

### æœ€ä½³å®è·µ

1. **ç‰ˆæœ¬ç®¡ç†**: ä½¿ç”¨è¯­ä¹‰åŒ–ç‰ˆæœ¬å·ï¼Œæ˜ç¡®æ ‡è¯†ç ´åæ€§å˜æ›´
2. **å¤‡ä»½ç­–ç•¥**: è¿ç§»å‰è‡ªåŠ¨å¤‡ä»½ï¼Œæ”¯æŒå¿«é€Ÿå›æ»š
3. **éªŒè¯æœºåˆ¶**: æ¯ä¸ªè¿ç§»è„šæœ¬éƒ½è¦æœ‰éªŒè¯é€»è¾‘
4. **é”™è¯¯å¤„ç†**: å®ç°å®Œå–„çš„é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶
5. **æ€§èƒ½ä¼˜åŒ–**: å¤§æ•°æ®é‡è¿ç§»è¦è€ƒè™‘åˆ†æ‰¹å¤„ç†
6. **å…¼å®¹æ€§**: ä¿æŒå‘å‰å’Œå‘åå…¼å®¹æ€§
7. **ç›‘æ§å‘Šè­¦**: ç›‘æ§è¿ç§»è¿‡ç¨‹ï¼ŒåŠæ—¶å‘ç°é—®é¢˜
8. **æ–‡æ¡£è®°å½•**: è¯¦ç»†è®°å½•æ¯æ¬¡è¿ç§»çš„å˜æ›´å†…å®¹

é€šè¿‡åˆç†çš„æ•°æ®è¿ç§»ç­–ç•¥ï¼Œå¯ä»¥ç¡®ä¿åº”ç”¨å‡çº§è¿‡ç¨‹çš„å®‰å…¨æ€§å’Œå¯é æ€§ï¼Œä¸ºç”¨æˆ·æä¾›å¹³æ»‘çš„å‡çº§ä½“éªŒã€‚
